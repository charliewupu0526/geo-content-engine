"""
OpenAI GPT-5 Service - Content generation and analysis
"""

from openai import OpenAI
from typing import Optional, Dict, Any, List
import json
from api.config import get_settings

class OpenAIService:
    """Service wrapper for OpenAI GPT-5 API"""
    
    def __init__(self):
        settings = get_settings()
        self.client = OpenAI(api_key=settings.openai_api_key)
        self.model = "gpt-5"  # GPT-5 æ¨¡åž‹
        self.fast_model = "gpt-5-turbo"  # å¿«é€Ÿç‰ˆæœ¬ç”¨äºŽç®€å•ä»»åŠ¡
    
    async def analyze_company_content(
        self, 
        content: str, 
        company_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analyze scraped content to extract company information
        """
        prompt = f"""
        åˆ†æžä»¥ä¸‹ç½‘ç«™å†…å®¹ï¼Œæå–å…¬å¸ä¿¡æ¯ã€‚è¯·ç”¨ JSON æ ¼å¼è¿”å›žï¼š

        {content[:8000]}

        è¯·æå–ï¼š
        1. company_name: å…¬å¸åç§°
        2. industry: æ‰€å±žè¡Œä¸š
        3. products_services: äº§å“æˆ–æœåŠ¡åˆ—è¡¨
        4. target_audience: ç›®æ ‡å—ä¼—
        5. unique_selling_points: ç‹¬ç‰¹å–ç‚¹
        6. key_features: æ ¸å¿ƒåŠŸèƒ½/ç‰¹ç‚¹

        è¯·ç›´æŽ¥è¿”å›ž JSONï¼Œä¸è¦åŒ…å« markdown ä»£ç å—ã€‚
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.fast_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¼ä¸šåˆ†æžå¸ˆï¼Œæ“…é•¿ä»Žç½‘ç«™å†…å®¹ä¸­æå–ç»“æž„åŒ–ä¿¡æ¯ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            return {
                "company_name": company_name or "Unknown",
                "industry": "Technology",
                "products_services": [],
                "target_audience": "Businesses",
                "unique_selling_points": [],
                "key_features": [],
                "error": str(e)
            }
    
    async def generate_gap_analysis(
        self, 
        company_profile: Dict[str, Any],
        competitor_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Generate GEO gap analysis comparing company to competitors
        """
        competitor_summary = "\n".join([
            f"ç«žå“ {i+1} ({c['url']}): {c.get('content', 'N/A')[:2000]}"
            for i, c in enumerate(competitor_data) if c.get("success")
        ])
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ GEO (Generative Engine Optimization) åˆ†æžå¸ˆã€‚
        
        åŸºäºŽä»¥ä¸‹ä¿¡æ¯è¿›è¡Œå·®è·åˆ†æžï¼š
        
        ## æˆ‘æ–¹ä¼ä¸šç”»åƒï¼š
        {json.dumps(company_profile, ensure_ascii=False)}
        
        ## ç«žå“å†…å®¹åˆ†æžï¼š
        {competitor_summary}
        
        è¯·ç”Ÿæˆè¯¦ç»†çš„å·®è·åˆ†æžæŠ¥å‘Šï¼Œè¿”å›ž JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹ç»“æž„ï¼š
        
        {{
            "summary": "æ ¸å¿ƒè¯Šæ–­ç»“è®º",
            "competitorGaps": [
                {{"dimension": "ç»´åº¦å", "description": "å·®è·æè¿°", "impact": "å½±å“ç¨‹åº¦"}}
            ],
            "missingKeywords": [
                {{"cluster": "å…³é”®è¯ç°‡", "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"], "priority": "ä¼˜å…ˆçº§"}}
            ],
            "structuralGaps": [
                {{"component": "ç»„ä»¶ç±»åž‹", "whyNeeded": "ä¸ºä½•éœ€è¦"}}
            ],
            "suggestions": [
                {{"action": "å»ºè®®è¡ŒåŠ¨", "timeframe": "æ—¶é—´æ¡†æž¶", "expectedOutcome": "é¢„æœŸæ•ˆæžœ"}}
            ]
        }}
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ GEO ä¼˜åŒ–ä¸“å®¶ï¼Œä¸“æ³¨äºŽå¸®åŠ©ä¼ä¸šåœ¨ AI æœç´¢å¼•æ“Žä¸­èŽ·å¾—æ›´å¥½çš„å¼•ç”¨å’ŒæŽ’åã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            # Return mock data on failure
            return {
                "summary": "è¯Šæ–­ç»“è®ºï¼šå½“å‰ç«™ç‚¹åœ¨ç”Ÿæˆå¼å¼•æ“Žä¸­çš„'å®žä½“æƒå¨åº¦'ä¸è¶³",
                "competitorGaps": [
                    {"dimension": "å®žä½“æƒé‡", "description": "ç«žå“å¼•ç”¨ 2024 æ ‡å‡†ï¼Œæˆ‘æ–¹ç¼ºä¹è§„èŒƒå¼•ç”¨ã€‚", "impact": "æžé«˜"}
                ],
                "missingKeywords": [
                    {"cluster": "æŠ€æœ¯åº•å±‚", "keywords": ["RAG å¯¹é½", "Schema FAQ", "å†…å®¹å¹»è§‰æŠ‘åˆ¶"], "priority": "é«˜"}
                ],
                "structuralGaps": [
                    {"component": "Markdown è¡¨æ ¼", "whyNeeded": "Perplexity ä¼˜å…ˆæŠ“å–è¡¨æ ¼é”®å€¼å¯¹ã€‚"}
                ],
                "suggestions": [
                    {"action": "é‡æž„æ ¸å¿ƒåšå®¢ä¸ºæ•°æ®çŸ©é˜µ", "timeframe": "3å¤©", "expectedOutcome": "æå‡è¦†ç›–çŽ‡"}
                ],
                "error": str(e)
            }
    
    async def generate_company_profile(
        self,
        company_name: str,
        domain: str,
        scraped_content: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a comprehensive company profile for GEO optimization
        """
        content_context = ""
        if scraped_content:
            content_context = f"åŸºäºŽçˆ¬å–çš„å†…å®¹ï¼š{str(scraped_content)[:3000]}"
        
        prompt = f"""
        ä¸ºä»¥ä¸‹ä¼ä¸šç”Ÿæˆä¸€ä»½ GEO ä¼˜åŒ–æˆ˜ç•¥ç”»åƒï¼š
        
        ä¼ä¸šåç§°ï¼š{company_name}
        åŸŸåï¼š{domain}
        {content_context}
        
        è¯·ç”Ÿæˆæ·±åº¦ä¼ä¸šç”»åƒï¼ŒåŒ…å«ï¼š
        
        1. å“ç‰Œæ ¸å¿ƒå®šä½ (Brand Positioning)
        2. æ ¸å¿ƒäº§å“/æœåŠ¡çŸ©é˜µ (Product Matrix)
        3. å—ä¼—ç¾¤ä½“ä¸Žæœç´¢åœºæ™¯ (Audience & Scenarios)
        4. è¡Œä¸šå®žä½“å…³è” (Entity Graph)
        5. GEO ç­–ç•¥åå¥½ (Strategy Markers)
        
        è¯·ç”¨ç»“æž„åŒ–çš„ä¸­æ–‡æ–‡æœ¬è¿”å›žï¼Œä»¥ä¾¿åœ¨ AI æœç´¢å¼•æ“Žä¸­å»ºç«‹å®žä½“æƒå¨ã€‚
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å“ç‰Œæˆ˜ç•¥ä¸“å®¶ï¼Œæ“…é•¿ä¸ºä¼ä¸šåˆ¶å®š GEO ä¼˜åŒ–æˆ˜ç•¥ã€‚"},
                    {"role": "user", "content": prompt}
                ]
            )
            return {
                "company_name": company_name,
                "domain": domain,
                "profile_text": response.choices[0].message.content,
                "generated_at": str(__import__('datetime').datetime.now())
            }
        except Exception as e:
            return {
                "company_name": company_name,
                "domain": domain,
                "profile_text": f"[æ·±åº¦ä¼ä¸šç”»åƒä¸Ž GEO æˆ˜ç•¥å¯¹é½æŠ¥å‘Š]\n\nå“ç‰Œåç§°ï¼š{company_name}\nå®˜æ–¹åŸŸåï¼š{domain}\n\n(è‡ªåŠ¨ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¡«å†™)",
                "error": str(e)
            }
    
    async def generate_content(
        self,
        title: str,
        content_type: str,
        profile: Dict[str, Any]
    ) -> str:
        """
        Generate content based on title and type (Article or Social)
        """
        if content_type == "Article":
            system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ SEO/GEO å†…å®¹ä½œå®¶ï¼Œæ“…é•¿æ’°å†™ç»“æž„åŒ–çš„æ·±åº¦æŠ€æœ¯æ–‡ç« ã€‚"
            prompt = f"""
            æ’°å†™ä¸€ç¯‡æ·±åº¦ GEO ä¼˜åŒ–æ–‡ç« ï¼Œæ ‡é¢˜ï¼š"{title}"
            
            ä¼ä¸šèƒŒæ™¯ï¼š{json.dumps(profile, ensure_ascii=False)}
            
            è¦æ±‚ï¼š
            - åŒ…å« Markdown æ ¼å¼çš„è¡¨æ ¼å¯¹æ¯”
            - åŒ…å« FAQ æ¨¡å—ï¼ˆè‡³å°‘ 3 ä¸ªé—®ç­”ï¼‰
            - å¼•ç”¨è¡Œä¸šæƒå¨æ•°æ®
            - ä½¿ç”¨ E-E-A-T æ¡†æž¶ç¡®ä¿å†…å®¹æƒå¨æ€§
            - 2000-2500 å­—
            """
            model = self.model
        else:  # Social
            system_prompt = "ä½ æ˜¯ä¸€ä½ç¤¾äº¤åª’ä½“è¥é”€ä¸“å®¶ï¼Œæ“…é•¿æ’°å†™å¼•äººæ³¨ç›®çš„çŸ­æ–‡æ¡ˆã€‚"
            prompt = f"""
            æ’°å†™ä¸€æ¡ç¤¾äº¤åª’ä½“çˆ†æ¬¾çŸ­æ–‡ï¼Œè¯é¢˜ï¼š"{title}"
            
            ä¼ä¸šèƒŒæ™¯ï¼š{json.dumps(profile, ensure_ascii=False)}
            
            è¦æ±‚ï¼š
            - ä½¿ç”¨ Emoji å¢žå¼ºå¯è¯»æ€§
            - åŒ…å«çƒ­é—¨æ ‡ç­¾ (hashtags)
            - é€‚åˆ Instagram/Twitter
            - 200-300 å­—
            - æœ‰æ˜Žç¡®çš„ CTAï¼ˆè¡ŒåŠ¨å·å¬ï¼‰
            """
            model = self.fast_model
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ]
            )
            return response.choices[0].message.content
        except Exception as e:
            if content_type == "Article":
                return f"# {title}\n\n## æ ¸å¿ƒè§è§£\n\nå†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}"
            else:
                return f"{title}\n\nðŸš€ å†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}\n\n#GEO #AI #Marketing"


# Singleton instance
_openai_service: Optional[OpenAIService] = None

def get_openai_service() -> OpenAIService:
    """Get or create OpenAI service instance"""
    global _openai_service
    if _openai_service is None:
        _openai_service = OpenAIService()
    return _openai_service

# ä¿æŒå‘åŽå…¼å®¹
def get_gemini_service() -> OpenAIService:
    """Alias for backward compatibility"""
    return get_openai_service()
